#!/usr/bin/env python3

import copy
import json
import jsonref
import os
import shutil
import sys

basedir = "."


def prepare_dir(name):
    """"""
    global basedir
    subdir = os.path.join(basedir, name)
    shutil.rmtree(subdir, ignore_errors=True)
    os.mkdir(subdir)
    return


def process_definitions(data):
    """Dump definitions.

    Dump definitions into the /defs/ subdirectory with definition key as the
    file name.
    """
    prepare_dir("defs")
    definitions = data['definitions']
    for k, v in data['definitions'].items():
        # skip deprecated definitions
        if k.startswith("io.k8s.kubernetes.pkg.apis."):
            print("\033[31m skipping %s \033[0m" % k)
            continue
        if k.startswith("io.k8s.kubernetes.pkg.api.v1."):
            print("\033[31m skipping %s \033[0m" % k)
            continue

        print("Dumping definition: %s" % k)

        # inject group version kind
        gvk = v.get("x-kubernetes-group-version-kind", [])
        if len(gvk) > 1:
            print("\033[31m %s: %d GVKs \033[0m" % (k, len(gvk)))
        if len(gvk) == 1:
            group = gvk[0]["group"]
            version = gvk[0]["version"]
            kind = gvk[0]["kind"]
            if group == "":
                v["properties"]["apiVersion"]["enum"] = [version]
            else:
                v["properties"]["apiVersion"]["enum"] = [group + "/" + version]
            v["properties"]["kind"]["enum"] = [kind]

            # make 'apiVersion', 'kind' required.
            required = v.get("required", [])
            required.extend(["apiVersion", "kind"])
            v["required"] = required

        if "properties" in v:
            v["type"] = "object"

        fn = os.path.join(basedir, "defs", k + ".json")
        with open(fn, "w") as f:
            f.write(json.dumps(v, indent=2, sort_keys=True))


def process_operations(data):
    prepare_dir("ops")
    paths = data['paths']
    for path, pathd in paths.items():
        print("Processing path: %s" % path)
        path_params = pathd.get("parameters", [])
        for op, opd in pathd.items():
            if op == "parameters":
                continue
            op_id = opd['operationId']

            opdata = copy.deepcopy(opd)
            # 'op_params' is the parameters defined solely for this operation.
            op_params = opd.get('parameters', [])
            for p in path_params:
                if "$ref" in p:
                    # #/parameters/<name>
                    ref = p["$ref"][13:]
                    pd = data["parameters"][ref]
                else:
                    pd = p

                # skip non-required query param for post requests
                if pd["in"] == "query" and op == "post":
                    required = pd.get("required", False)
                    if not required:
                        continue
                op_params.append(p)

            opdata["verb"] = op
            opdata["path"] = path
            if op_params:
                opdata["parameters"] = op_params

            print("  Operation: %s %s %s" % (op_id, op, path))
            fn = os.path.join(basedir, "ops", op_id + ".json")
            with open(fn, "w") as f:
                f.write(json.dumps(opdata, indent=2, sort_keys=True))


def process_security(data):
    prepare_dir("security")

    security = data.get('security', [])
    fn = os.path.join(basedir, "security", "security.json")
    with open(fn, "w") as f:
        f.write(json.dumps(security, indent=2, sort_keys=True))

    securityDefs = data.get('securityDefinitions', {})
    fn = os.path.join(basedir, "security", "securityDefinitions.json")
    with open(fn, "w") as f:
        f.write(json.dumps(securityDefs, indent=2, sort_keys=True))


def process_parameters(data):
    prepare_dir("parameters")

    params = data.get('parameters', [])
    fn = os.path.join(basedir, "parameters", "parameters.json")
    with open(fn, "w") as f:
        f.write(json.dumps(params, indent=2, sort_keys=True))


def process_basic(data):
    prepare_dir("basic")

    version = data.get('swagger', "2.0")
    info = data.get("info", {})
    basic = {
        "swagger": version
    }
    if info:
        basic["info"] = info
    fn = os.path.join(basedir, "basic", "basic.json")
    with open(fn, "w") as f:
        f.write(json.dumps(basic, indent=2, sort_keys=True))


def cross_compare(existing, check):
    c = copy.deepcopy(check)
    if "required" not in c:
        c["required"] = False

    if c != existing:
        print("\033[31mDeviated param definition: %r \033[0m" % check)
        print("\033[31m    %r \033[0m" % existing)
    return

def extract_parameters(data):
    common_params = [
        "allowWatchBookmarks",
        "continue",
        "dryRun",
        "exact",
        "export",
        "fieldManager",  # since 1.14
        "fieldSelector",
        "fieldValidation",   # since 1.23
        "force",  # since 1.14
        "gracePeriodSeconds",
        "includeUninitialized",
        "labelSelector",
        "limit",
        "namespace",
        "orphanDependents",
        "pretty",
        "propagationPolicy",
        "resourceVersion",
        "resourceVersionMatch", # since 1.19
        "sendInitialEvents", # since 1.27
        "timeoutSeconds",
        "watch",
    ]
    param_spec = {}
    paths = data['paths']
    
    for path, pathd in paths.items():
        print("Processing path: %s" % path)
        for op, opd in pathd.items():
            if op == "parameters":
                params = []
                # opd is the list of parameters defined for a path
                for p in opd:
                    p_name = p["name"]
                    if p_name in common_params:
                        # accumulate the top leve list
                        if p_name not in param_spec:
                            p_copy = copy.deepcopy(p)
                            p_copy["required"] = False
                            if p.get("required", False) == True:
                                p_copy["required"] = True

                            param_spec[p_name] = p_copy
                        else:
                            cross_compare(param_spec[p_name], p)

                        # make it a reference
                        params.append({"$ref": "#/parameters/" + p_name})
                    else:
                        p_copy = copy.deepcopy(p)
                        params.append(p_copy)
                data["paths"][path]["parameters"] = params
            # op is a verb
            else:
                # param_list is the list of parameters defined for an operation
                param_list = opd.get("parameters", [])
                if len(param_list) == 0:
                    continue
                params = []
                for p in param_list:
                    p_name = p["name"]
                    if p_name in common_params:
                        # Patch operation has a different description for
                        # fieldManager, we define a separate item for it
                        if p_name == "fieldManager":
                            if op == "patch":
                                p_name = "fieldManagerPatch"

                        # accumulate the top leve list
                        if p_name not in param_spec:
                            p_copy = copy.deepcopy(p)
                            p_copy["required"] = False
                            param_spec[p_name] = p_copy
                            if p.get("required", False) == True:
                                p_copy["required"] = True
                        else:
                            cross_compare(param_spec[p_name], p)

                        # make it a reference
                        params.append({"$ref": "#/parameters/" + p_name})
                    else:
                        p_copy = copy.deepcopy(p)
                        params.append(p_copy)
                data["paths"][path][op]["parameters"] = params

    data["parameters"] = param_spec
    return data


def main():
    global basedir

    if len(sys.argv) < 2:
        print("Usage: decompose <swagger.json>")
        sys.exit(-1)

    try:
        f = open(sys.argv[1])
    except Exception:
        print("ERROR: Cannot find or open the input file %s" % sys.argv[1])
        sys.exit(-2)

    basedir = os.path.dirname(sys.argv[1])
    basename, ext = os.path.splitext(sys.argv[1])
    try:
        data = json.load(f)
    finally:
        f.close()

    # remove circular reference
    data["definitions"].pop("io.k8s.apiextensions-apiserver.pkg.apis."
                            "apiextensions.v1beta1.JSONSchemaProps", None)
    data["definitions"].pop("io.k8s.apiextensions-apiserver.pkg.apis."
                            "apiextensions.v1.JSONSchemaProps", None)
    crv_v1beta1 = ("io.k8s.apiextensions-apiserver.pkg.apis." +
                   "apiextensions.v1beta1.CustomResourceValidation")
    crv_d = data["definitions"].get(crv_v1beta1, None)
    if crv_d:
        p = data["definitions"][crv_v1beta1]["properties"]
        p["openAPIV3Schema"]["type"] = "object"
        p["openAPIV3Schema"].pop("$ref", None)

    crv_v1 = ("io.k8s.apiextensions-apiserver.pkg.apis." +
                   "apiextensions.v1.CustomResourceValidation")
    crv_d = data["definitions"].get(crv_v1, None)
    if crv_d:
        p = data["definitions"][crv_v1]["properties"]
        p["openAPIV3Schema"]["type"] = "object"
        p["openAPIV3Schema"].pop("$ref", None)

    # extract parameters into spec level
    data = extract_parameters(data)
    newfile = basename + "_tailored" + ext
    with open(newfile, "w") as f:
        f.write(json.dumps(data, indent=2, sort_keys=True))

    process_basic(data)
    process_definitions(data)
    process_operations(data)
    process_security(data)
    process_parameters(data)

if __name__ == "__main__":
    main()
